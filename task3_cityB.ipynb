{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Location Prediction - City B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We only consider the first 30 days (75 days in total) of the CityB dataset to reduce the data processing load. We believe this will not affect the result of analysis because the first 30 days is long enough capture the significant trends and patterns that are relevant to the analysis.\n",
    "The original dataset consists of 24,375,898 rows. After the selection, the number of rows are reduced to 9,736,068, approximately one-third of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set TensorFlow to use multiple threads\n",
    "os.environ['OMP_NUM_THREADS'] = '20'  # Set this to the number of CPU cores you want to use\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Disable TensorFlow debug info\n",
    "\n",
    "# To configure intra-op and inter-op parallelism\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load data\n",
    "# Path to the dataset subfolder\n",
    "data_path = './dataset'\n",
    "\n",
    "# List all files in the subfolder\n",
    "# file_paths = [os.path.join(data_path, file) for file in os.listdir(data_path) if file.endswith('.csv.gz')]\n",
    "file_path = './dataset\\\\cityB_challengedata.csv.gz'\n",
    "city_name = os.path.basename(file_path).split('_')[0]\n",
    "# data = pd.read_csv(file_path, compression='gzip', nrows = 500000)\n",
    "data = pd.read_csv(file_path, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of days: 75\n",
      "Total number of participants: 25000\n",
      "Data size: 24375898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of days: {len(data['d'].unique())}\")\n",
    "print(f\"Total number of participants: {len(data['uid'].unique())}\")\n",
    "print(f\"Data size: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=3):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for uid, group in data.groupby('uid'):\n",
    "        coords = group[['x', 'y']].values\n",
    "        for i in range(len(coords) - seq_length):\n",
    "            sequences.append(coords[i:i + seq_length])  # Input sequence\n",
    "            labels.append(coords[i + seq_length])  # Target value\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input sequences (X): (9661384, 3, 2)\n",
      "Shape of labels (y): (9661384, 2)\n",
      "Size of training data: 9736068\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "processed_data = data[data['d'] < 30]\n",
    "\n",
    "# Generate sequences and labels\n",
    "X, y = create_sequences(processed_data)\n",
    "\n",
    "# Display the shape of the prepared data\n",
    "print(f\"Shape of input sequences (X): {X.shape}\")\n",
    "print(f\"Shape of labels (y): {y.shape}\")\n",
    "print(f\"Size of training data: {len(processed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shi_h\\anaconda3\\envs\\louvain\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52678/52678\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - loss: 95.0339\n",
      "Epoch 2/10\n",
      "\u001b[1m  385/52678\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 2ms/step - loss: 54.6033"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define LSTM model architecture\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    Dense(2)  # Output layer with 2 units for predicting (x, y)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=3, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the model for future use\n",
    "model.save('trajectory_predictor.h5')\n",
    "\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input sequences (X_test): (294787, 3, 2)\n",
      "Shape of labels (y_test): (294787, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate sequences and labels\n",
    "# X_test, y_test = create_sequences(data[(data['d'] > 30) & (data['d'] < 40)])\n",
    "X_test, y_test = create_sequences(data[(data['d'] > 30)])\n",
    "\n",
    "# Display the shape of the prepared data\n",
    "print(f\"Shape of input sequences (X_test): {X_test.shape}\")\n",
    "print(f\"Shape of labels (y_test): {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9213/9213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step\n",
      "Accuracy @ k: {1: 0.08487823411480154, 2: 0.31254770393538384, 3: 0.5241886514669915, 4: 0.6382710228062974, 5: 0.7038132617788437}\n"
     ]
    }
   ],
   "source": [
    "def compute_acc_at_k(model, X_test, y_test, k_values=[1, 2, 3, 4, 5]):\n",
    "    \"\"\"\n",
    "    Compute Accuracy at k (Acc@k).\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model.\n",
    "        X_test: Test input data, shape (num_samples, 3, 2).\n",
    "        y_test: Ground truth labels, shape (num_samples, 2).\n",
    "        k_values: List of k values to compute Acc@k.\n",
    "\n",
    "    Returns:\n",
    "        acc_at_k: Dictionary with Acc@k for each k.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_test)  # Shape: (num_samples, 2)\n",
    "    acc_at_k = {k: 0 for k in k_values}\n",
    "    num_samples = X_test.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        true_target = y_test[i]  # True target (x, y)\n",
    "        pred = predictions[i]  # Predicted location (x, y)\n",
    "\n",
    "        # Compute Euclidean distances between prediction and true target\n",
    "        distance = np.linalg.norm(pred - true_target)\n",
    "\n",
    "        # Check if the distance qualifies as a \"hit\" within k thresholds\n",
    "        for k in k_values:\n",
    "            if distance <= k:  # Define threshold based on domain context\n",
    "                acc_at_k[k] += 1\n",
    "\n",
    "    # Normalize Acc@k\n",
    "    acc_at_k = {k: acc / num_samples for k, acc in acc_at_k.items()}\n",
    "    return acc_at_k\n",
    "\n",
    "# Example usage:\n",
    "acc_at_k = compute_acc_at_k(model, X_test, y_test)\n",
    "# acc_at_k = compute_acc_at_k(model, X, y)\n",
    "print(f\"Accuracy @ k: {acc_at_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9213/9213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1ms/step\n",
      "Mean Reciprocal Rank (MRR): 0.5\n"
     ]
    }
   ],
   "source": [
    "def compute_mrr(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Compute Mean Reciprocal Rank (MRR).\n",
    "\n",
    "    Args:\n",
    "        model: Trained Keras model.\n",
    "        X_test: Test input data, shape (num_samples, 3, 2).\n",
    "        y_test: Ground truth labels, shape (num_samples, 2).\n",
    "\n",
    "    Returns:\n",
    "        mrr: Mean Reciprocal Rank (MRR).\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_test)  # Shape: (num_samples, 2)\n",
    "    reciprocal_ranks = []\n",
    "    num_samples = X_test.shape[0]\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        true_target = y_test[i]  # True target (x, y)\n",
    "        pred = predictions[i]  # Predicted location (x, y)\n",
    "\n",
    "        # Compute Euclidean distance between prediction and true target\n",
    "        distance = np.linalg.norm(pred - true_target)\n",
    "\n",
    "        # Rank is determined based on distance (assume sorted rank)\n",
    "        rank = 1 if distance < 1e-5 else 2  # Adjust ranking logic as needed\n",
    "        reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "    # Compute MRR\n",
    "    mrr = np.mean(reciprocal_ranks)\n",
    "    return mrr\n",
    "\n",
    "# Example usage:\n",
    "mrr = compute_mrr(model, X_test, y_test)\n",
    "# mrr = compute_mrr(model, X, y)\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "louvain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
